# üèóÔ∏è **Transformaci√≥n de Datos con Pipelines**

## **Autor:** Carolina P√©rez Molina

## üßæ **Descripci√≥n**
Este proyecto tiene como objetivo la limpieza y transformaci√≥n de datos utilizando sklearn.pipeline. Se trabaja con el conjunto de datos `dirty_cafe_sales.csv`, realizando un an√°lisis exploratorio de datos (EDA), pues esto nos mostrar√° los errores que existen en el Dataframe, y luego seg√∫n los errores encontrados se aplicaron transformaciones con pipelines.

## üìä **Datos**
El dataset `dirty_cafe_sales.csv` contiene 10,000 registros sobre ventas en una cafeter√≠a. Sin embargo, presenta problemas de calidad como valores faltantes, errores tipogr√°ficos y datos inconsistentes.

- **Transaction ID:** Identificador √∫nico de cada transacci√≥n.
- **Item:** Producto comprado (ej. caf√©, pastel, galleta). 
- **Quantity:** Cantidad de unidades compradas de un producto.
- **Price Per Unit:** Precio unitario del producto.
- **Total Spent:** Precio total de la transacci√≥n.
- **Payment Method:** M√©todo de pago usado (ej. tarjeta de cr√©dito, efectivo, billetera digital).
- **Location:** Ubicaci√≥n de la compra (ej. "In-store", "Takeaway").
- **Transaction Date:** Fecha de la compra.

## üõ†Ô∏è **Proceso realizado**
- Se realiz√≥ un an√°lisis exploratorio de datos (EDA) para observar los datos e identificar los errores que se corregir√≠an con pipelines.
- En el EDA se identific√≥ que todas las columnas fueron le√≠das como object, por lo que se modificaron a `category` y `float` para poder aplicar transformaciones con pipelines.
- Luego se realizaron trandormaciones con pipelines:
     - Para los valores faltantes en los datos num√©ricos, se imputaron utilizando el promedio de los dem√°s valores.
     - No se cambi√≥ la escala de los n√∫meros, ya que esto podr√≠a afectar la interpretaci√≥n de los datos, dado que las variables num√©ricas corresponden a precios y cantidades.
     - Para las variables categ√≥ricas con datos faltantes, se imput√≥ utilizando la moda.
     - Se aplic√≥ la transformaci√≥n `One Hot Encoding`, pero solo a los m√©todos de pago y la ubicaci√≥n de la compra. No se utiliz√≥ en la variable `Item` para evitar la generaci√≥n de demasiadas columnas, lo que dificultar√≠a la interpretaci√≥n de los datos. Adem√°s, para evitar la trampa de las variables ficticias, se elimin√≥ la primera columna generada, asumiendo que si una fila tiene 0, el 1 corresponde a la categor√≠a faltante. En este caso, la categor√≠a impl√≠cita para la ubicaci√≥n es `In-store` y para el m√©todo de pago es `Cash`. 
     - Finalmente, se realiz√≥ una transformaci√≥n en la fecha, dividiendo la columna en d√≠a, mes y a√±o.

## üìà **Concluisones**
- La transformaci√≥n de variables categ√≥ricas permiti√≥ estandarizar los datos y facilitar su uso en an√°lisis futuros sin generar un exceso de columnas innecesarias.
- La estrategia de imputaci√≥n de valores faltantes con la moda y el promedio garantiz√≥ que no se perdiera informaci√≥n relevante en el dataset.
- No escalar los datos num√©ricos fue una decisi√≥n acertada, ya que al tratarse de precios y cantidades, conservar su magnitud original permite una mejor interpretaci√≥n.
- La transformaci√≥n de fechas en d√≠a, mes y a√±o facilita su uso en an√°lisis temporales y permite extraer patrones estacionales en las ventas.
- El uso de pipelines optimiz√≥ el proceso de limpieza y transformaci√≥n, haciendo que el preprocesamiento sea m√°s eficiente y reproducible para futuros datasets.